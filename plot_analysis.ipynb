{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2ba20c-a8a6-4716-b3ba-d818b46c8a42",
   "metadata": {},
   "source": [
    "#  Trend Analysis for the RAJA Performance Suite: CSV Data Visualization\n",
    "\n",
    "Understanding the performance characteristics of computational kernels is critical for optimizing scientific applications on high-performance computing (HPC) systems. The RAJA Performance Suite (RAJAPerf)[1] provides a collection of key computational kernels relevant to Lawrence Livermore National Laboratory (LLNL). This notebook performs a visual analysis of RAJAPerf kernel performance across different execution configurations on LLNL’s [Lassen supercomputer](https://hpc.llnl.gov/hardware/compute-platforms/lassen).  \n",
    "\n",
    "The performance data used in this analysis is derived from the `.csv` files generated by `csv_generation.ipynb`, which processes `.cali` files collected from RAJAPerf runs through the [Caliper profiler](https://software.llnl.gov/Caliper/) on both Lassen’s POWER9 CPUs and V100 GPUs. These `.csv` files capture performance metrics for different problem sizes and numbers of MPI ranks.  \n",
    "\n",
    "This notebook visualizes performance trends across kernels by generating surface plots and other comparative visualizations. By analyzing these plots, users can identify performance scaling trends, pinpoint bottlenecks, and gain insights into how problem sizes and parallel execution strategies affect kernel execution time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d73689-fdb2-4c62-9e3a-9f7318092871",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e02b4d-c995-4639-a63f-700c1652871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "from glob import glob\n",
    "from warnings import simplefilter\n",
    "import os\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Ignore pandas performance warnings\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b952ce5-8341-40df-b3fd-552c2ac1cdc9",
   "metadata": {},
   "source": [
    "## 2.Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c3e56-f63a-4a87-a973-c4ffdb546640",
   "metadata": {},
   "source": [
    "The plot_kernel function generates 3D surface plots to visualize the performance of RAJAPerf kernels, mapping problem size, rank, and runtime. It allows customization of the plot, including the colorscale, contour lines, axis labels, and optional logarithmic scaling for any of the axes. The function retrieves the runtime data for the specified kernel and, if enabled, overlays contour lines to highlight varying levels of runtime. Additional customization options, such as contour size, color, and plot titles, can be provided via keyword arguments. The function outputs an interactive plot using Plotly, making it an effective tool for analyzing kernel performance across different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37acada-b69d-4037-828a-ebc68c129211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main plotting function\n",
    "def plot_kernel(focus_kernel, colorscale='Viridis', enable_contours=False, logscale=[\"none\"], **kwargs):\n",
    "    global X\n",
    "    global Y\n",
    "    \n",
    "    # Contour Configuration\n",
    "    contours = None\n",
    "    contour_size = kwargs.get('contour_size', 40)\n",
    "    contour_color = kwargs.get('contour_color', \"black\")\n",
    "\n",
    "    # Axis naming configuration\n",
    "    xaxis_title = kwargs.get('xaxis_title', \"Problem Size\")\n",
    "    yaxis_title = kwargs.get('yaxis_title', \"Ranks\")\n",
    "    zaxis_title = kwargs.get('zaxis_title', \"Runtime\")\n",
    "\n",
    "    title = kwargs.get('title', f'Kernel: {focus_kernel} Surface Map')\n",
    "    \n",
    "    z = get_z_matrix(focus_kernel)\n",
    "\n",
    "    custom_colorscale = colorscale\n",
    "\n",
    "    x = X\n",
    "    y = Y\n",
    "\n",
    "    # Apply logscale to if specified\n",
    "    for i in logscale:\n",
    "        if i.lower() == \"x\":\n",
    "            x = X.copy()\n",
    "            x = np.log10(x)\n",
    "        elif i.lower() == \"y\":\n",
    "            y = Y.copy()\n",
    "            y = np.log10(y)\n",
    "        elif i.lower() == \"z\":\n",
    "            z = np.log10(z)\n",
    "     \n",
    "    if enable_contours:\n",
    "        contours={\n",
    "            \"z\": {\n",
    "                \"show\": True,          \n",
    "                \"usecolormap\": False, \n",
    "                \"color\": contour_color,      \n",
    "                \"start\": z.min(),     \n",
    "                \"end\": z.max(),       \n",
    "                \"size\": (z.max() - z.min()) / contour_size, \n",
    "                \"highlightwidth\": 2  \n",
    "            }\n",
    "        }\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Surface(\n",
    "                z=z, x=x, y=y,\n",
    "                colorscale=custom_colorscale,\n",
    "                contours=contours\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(title=dict(text=title), autosize=False,\n",
    "                      width=800, height=800,\n",
    "                      margin=dict(l=65, r=50, b=65, t=90),\n",
    "                      scene=dict(\n",
    "                          xaxis_title=xaxis_title,\n",
    "                          yaxis_title=yaxis_title,\n",
    "                          zaxis_title=zaxis_title\n",
    "                      )\n",
    "                     )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed796c1d-0965-4e3d-a902-e9c835d34e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs the z matrix using runtime data\n",
    "def get_z_matrix(focus_kernel):\n",
    "    return np.array(kernel_agg_df[(focus_kernel, \"Avg time/rank\")]).reshape(X.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb002f0-bf7e-4be0-911b-2a2a3c0bae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows the plotting of a list of kernels\n",
    "def plot_kernels(focus_kernels, **kwargs):\n",
    "    for kernel in focus_kernels:\n",
    "        plot_kernel(kernel, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bddd0bc-00d2-4f48-bc06-7694916c2821",
   "metadata": {},
   "source": [
    "## 3. Reading and Processing All CSV Files for Kernel Analysis\n",
    "\n",
    "In this section, we load and process the relevant CSV files for kernel analysis. The type of execution—either CPU or GPU—is determined by the `TYPE_OF_RUN` variable. Each CSV file is read into a Pandas DataFrame, and all DataFrames are then concatenated column-wise into a single aggregated DataFrame for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536418b-a227-425f-920f-507323eb431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_OF_RUN = \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b488b-d716-429a-9813-9821049e540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_OF_RUN == \"CPU\":\n",
    "    DATA_ROOT = \"csv_files/raw/lassen/cpu/\"\n",
    "elif TYPE_OF_RUN == \"GPU\":\n",
    "    DATA_ROOT = \"csv_files/raw/lassen/gpu/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab60b38-4a91-4b69-ba7a-8a4a95737ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv files\n",
    "csv_files = glob(DATA_ROOT + \"*\")\n",
    "kernel_names = [os.path.basename(i)[7:-4] for i in csv_files]\n",
    "\n",
    "# Create a dataframe for each kernel and concatonate into a single multiindex dataframe\n",
    "kernel_dataframes = {}\n",
    "for idx, file in enumerate(csv_files):\n",
    "    kernel_df = pd.read_csv(file)\n",
    "    kernel_dataframes[kernel_names[idx]] = kernel_df\n",
    "\n",
    "kernel_agg_df = pd.concat(kernel_dataframes, axis=1, names=[\"kernel_name\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51cba4-2fae-42cd-9105-520f77865150",
   "metadata": {},
   "source": [
    "## 4. Defining the the X and Y meshgrids.\n",
    "\n",
    "To construct the meshgrid needed for surface plots, we use the `Basic_INIT3` kernel to extract the range of problem sizes and MPI ranks. Since these values are consistent across all kernels, Basic_INIT3 serves as a representative reference. This information is then used to generate the X and Y meshgrids for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e24989-f94e-4e29-a824-0ca2936bba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_sizes = pd.unique(kernel_agg_df[(\"Basic_INIT3\", \"problem_sizes\")])\n",
    "n_ranks = pd.unique(kernel_agg_df[(\"Basic_INIT3\", \"ranks\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81d363-444c-442c-83de-a1aa135ae81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(problem_sizes, n_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f5f3d-1c77-4f98-9f69-6d6a7e1ddfba",
   "metadata": {},
   "source": [
    "## 5. Plotting the kernels based on top down bottlenecks.\n",
    "\n",
    "We conduct an initial plot analysis of selected RAJAPerf kernels based on their top-down breakdown categories [2], including Memory Bound, Core Bound, Bad Speculation, Retiring, and Mixture (both Memory and Core Bound). This classification helps in understanding the underlying performance characteristics of each kernel. Additionally, we perform a focused analysis on a subset of kernels that exhibited deviant behavior, deviating from the typical performance trends observed across the overall collection of kernels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01095d0f-33d2-4c3c-b0ad-0816dc935a35",
   "metadata": {},
   "source": [
    "### 5.1 Analysis of Memory Bound Kernels\n",
    "\n",
    "Memory-bound kernels experience performance limitations primarily due to delays in accessing data from memory, which causes execution units to remain idle while waiting for data to arrive. These stalls typically result from cache misses at various levels, including L1, L2, L3, or external memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bacb2-baa2-4db8-8961-fcd196b44a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_bound_kernels = [\n",
    "    \"Stream_TRIAD\",\n",
    "    \"Stream_DOT\",\n",
    "    \"Basic_INIT3\",\n",
    "    \"Algorithm_MEMCPY\",\n",
    "    \"Lcals_FIRST_SUM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e5b99-b87d-43b7-8bda-5cbd181e7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(memory_bound_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f21bbf-2a2a-4a7e-b60e-7b533af866a6",
   "metadata": {},
   "source": [
    "### 5.2 Analysis of Core Bound Kernels\n",
    "\n",
    "Core-bound kernels are constrained by execution resources within the CPU core, such as arithmetic logic units (ALUs) or vector processing units, leading to stalls when execution units are unable to keep up with the demand. These bottlenecks can be caused by inefficient instruction scheduling, dependencies between instructions, or underutilization of available execution ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afea8e9-2be9-46a2-ad68-c4ee1af0384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_bound_kernels = [\n",
    "    \"Basic_MAT_MAT_SHARED\",\n",
    "    \"Algorithm_REDUCE_SUM\",\n",
    "    \"Basic_TRAP_INT\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceea19-6ba9-4595-b8d3-7b9073434022",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(core_bound_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22730739-d842-4ed9-aee2-3f1f03c57f9f",
   "metadata": {},
   "source": [
    "### 5.3 Analysis of Bad Speculation Bound Kernels\n",
    "\n",
    "Bad speculation-bound kernels suffer performance degradation due to incorrect speculative execution, where the processor executes instructions along a mispredicted path and later discards them. This category includes penalties from branch mispredictions and machine clears caused by incorrect memory ordering speculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b39e64-e8e6-4ca4-b179-2b58fb6ce207",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_speculation_bound_kernels = [\n",
    "    \"Lcals_FIRST_MIN\",\n",
    "    \"Algorithm_SORT\", \n",
    "    \"Algorithm_SORTPAIRS\",\n",
    "    \"Basic_INDEXLIST_3LOOP\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e51d3f-b262-4c1c-b240-269a1b92014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(bad_speculation_bound_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1af36-970f-40e2-8fab-354c900715ec",
   "metadata": {},
   "source": [
    "### 5.4 Analysis of Retiring Bound Kernels\n",
    "\n",
    "Retiring-bound kernels efficiently utilize available execution resources, with a high proportion of issued micro-operations successfully completing and retiring. Ideally, maximizing the retiring fraction leads to higher instruction-per-cycle (IPC) performance, but further optimizations such as vectorization or reducing microcode assists may still improve efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6a7c4-7756-4b29-a900-214c7c610867",
   "metadata": {},
   "outputs": [],
   "source": [
    "retiring_bound_kernels = [\n",
    "    \"Apps_LTIMES\",\n",
    "    \"Apps_MASS3DEA\",\n",
    "    \"Polybench_HEAT_3D\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae74e14-2879-412d-97db-aa5bc7cb9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(retiring_bound_kernels, runtime_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1112d-07f5-498f-ae04-4c911315e833",
   "metadata": {},
   "source": [
    "### 5.5 Analysis of both Memory and Core Bound\n",
    "\n",
    "Kernels that are both memory and core bound exhibit performance limitations from both memory stalls and inefficient execution unit utilization, indicating that improvements are needed in both data access patterns and instruction scheduling. These workloads may require optimizations in cache usage, data locality, and better exploitation of parallelism in computation to alleviate bottlenecks in both areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60533d63-57a9-4a80-8e08-c1c71e3d2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_kernels = [\n",
    "    \"Basic_MULTI_REDUCE\",\n",
    "    \"Apps_FIR\",\n",
    "    \"Basic_REDUCE_STRUCT\",\n",
    "    \"Basic_TRAP_INT\",\n",
    "    \"Apps_VOL3D\",\n",
    "    \"Basic_PI_ATOMIC\",\n",
    "    \"Polybench_ADI\",\n",
    "    \"Stream_DOT\",\n",
    "    \"Apps_DEL_DOT_VEC_2D\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3b14d-5133-43a6-9659-5712ac3ce82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(mixture_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248ee73-d5b4-4202-b2c0-617dc67419ab",
   "metadata": {},
   "source": [
    "### 5.6 Analysis of Deviant Kernels\n",
    "\n",
    "The following kernels exhibited deviant surface behavior, distinguishing them from the majority of RAJAPerf kernels. They encompass a diverse range of top-down bottlenecks and may provide deeper insights into specific performance patterns, particularly in areas such as memory access and cache behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4977c-920b-413f-929e-da6038453609",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviant_kernels = [\n",
    "    \"Comm_HALO_PACKING\",\n",
    "    \"Comm_HALO_EXCHANGE\",\n",
    "    \"Basic_IF_QUAD\",\n",
    "    \"Basic_NESTED_INIT\",\n",
    "    \"Basic_INIT_VIEW1D\",\n",
    "    \"Basic_INIT_VIEW1D_OFFSET\",\n",
    "    \"Lcals_DIFF_PREDICT\",\n",
    "    \"Polybench_ATAX\",\n",
    "    \"Polybench_MVT\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b176b13-3d15-4d85-9766-bdf606eeba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(deviant_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e2e64-6206-4c9e-b6dc-9be2ea355616",
   "metadata": {},
   "source": [
    "## 6. References\n",
    "\n",
    "[1] O. Pearce, J. Burmark, R. Hornung, Befikir Bogale, I. Lumsden, M. McKinsey, D. Yokelson, D. Boehme, S. Brink, M. Taufer, and T. Scogland, “Raja performance suite: Performance portability analysis with caliper and thicket,” in Proceedings of SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis, Atlanta, GA, USA: IEEE Computer Society, Nov. 2024.\n",
    "\n",
    "[2] A. Yasin, “A top-down method for performance analysis and counters architecture,” in Proceedings of IEEE International Symposium on Performance Analysis of Systems and Software, Monterey, CA, USA: IEEE Computer Society, Mar. 2014."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Befikir Bogale"
   },
   {
    "name": "Ian Lumsden"
   },
   {
    "name": "Dalal Sukkari"
   },
   {
    "name": "Michela Taufer"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "title": "Trend Analysis for the RAJA Performance Suite: CSV Data Visualization"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
